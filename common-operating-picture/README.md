# Virtru Data Security Platform - Common Operational Picture

> [!WARNING]
> Virtru's DSP COP is a demonstration application and is not intended for production use out-of-the box.
> The current iteration is **in active development** and is not intended to be a fully-featured application.
>
> If you have received a copy of this application from Virtru, it is provided for demonstration purposes only.

The DSP COP is an application to demonstrate the following:

1. [Data-Centric Security](https://www.virtru.com/data-security-platform) (ABAC, ZTDF)
2. Schema-driven User Interfaces to drive TDF creation
3. Secure, platform-protected search of TDF'd data

Table of Contents

1. [Quick Start](#quick-start)
2. [Development and Contribution](#development-and-contribution)
3. [Run Locally](#run-locally)
4. [Production](#production)
5. [Schema Creation](#schema-creation)
6. [Known Issues](#known-issues)

## Quick Start

This applicaiton can be run in two modes:
1. `Lite` - Sits on top of an already-deployed DSP stack
   - Follow [lite-deployment.md](./deploy/lite/lite-deployment.md)
1. `Full` - Deploys a full DSP stack
   - Continue with this Readme.

## Development and Contribution

### Server

COP is powered by a backend built with the following technologies:

1. [Golang](https://go.dev/), with the binary containing two commands

   * `start` to [run the server](./cmd/startCmd.go)
   * `db` for enhanced development experience interacting [directly with the database, including mocks](./cmd/dbCmd.go)

2. [Connect](https://buf.build/blog/connect-a-better-grpc)

   * compatible with [gRPC](https://grpc.io/), HTTP, and [ConnectRPC](https://connectrpc.com/)
   * driven by proto definitions and protobufs (see [proto definition file](./proto/tdf_object/v1/tdf_object.proto))
   * generated by [buf](https://buf.build/) (see [buf.gen.yaml](./buf.gen.yaml) for Go code generation from protos)
   * more information available in [the protos section](#protos)

3. [PostgreSQL](https://www.postgresql.org/) with [schema diagram](./db/entityRelationshipDiagram.md)

   * enhanced geometry types provided by [PostGIS extension](https://postgis.net/)
   * schema management provided by [atlas](https://atlasgo.io/)
   * db interactivity driven by [sqlc](https://github.com/sqlc-dev/sqlc) (see [sqlc.yaml](./sqlc.yaml) and filed marked
    generated within [/db](./db/))

In order to serve both static files (frontend COP) and the API interactivity with the COP database, two ports are opened
on the COP Go server. These ports are configured within the `config.yaml` config file ([see example](./config.example.yaml)
and [Configuration](#configuration)).

### Configuration

The configuration file is mapped in `config.example.yaml` and can be located at specific locations
scoped to how you are running the application.

1. Project-level: `config.yaml`
2. User-level: `~/.dsp-cop/config.yaml`
3. System-level: `/etc/dsp-cop/config.yaml`

> [!NOTE]
> The DSP config (typically `dsp.yaml`) can be found and updated within the `dev.dsp.Dockerfile`.

#### New Configuration Options

If you add a new configuration option, please update the `config.example.yaml` file and document the
new option in the `/pkg/config/config.go` file as well as comments in the example file.

### Protos

Our native gRPC service functions are generated from `proto` definitions using [Buf](https://buf.build/docs/introduction).

The `Makefile` provides command scripts to invoke `Buf` with the `buf.gen.yaml` config, including server Go code and browser TypeScript (JavaScript-compatible) code.

For convenience, the `make toolcheck` script checks if you have the necessary dependencies for `proto -> gRPC` generation.

## Run Locally

To demonstrate the capabilities of DSP, there are two root-level files to provision the platform.

1. [`sample.federal_policy.yaml` DSP Policy](./sample.federal_policy.yaml)
    * Attributes (a Namespace, Definitions, Values)
    * Subject Mappings to entitle users and clients
2. [`sample.keycloak.yaml` Users and Clients](./sample.keycloak.yaml) to be loaded into Keycloak as the demo identityProvider (idP)

> [!NOTE]
> PostGIS uses a [community-maintained image](https://github.com/ImreSamu/docker-postgis#debian---bookworm--recommended)
> for compatibility.
> There is [an open issue](https://github.com/postgis/docker-postgis/issues/371) with the official image running on `amd64` architecture.

### Pre-requisites

1. Copy the config `cp config.example.yaml config.yaml`
2. Install necessary dependencies(only _one_ docker runtime is needed):
   1. Container runtime and compose
      * Docker + Docker Compose
      * [Colima (recommended)](https://github.com/abiosoft/colima)
      * [Rancher Desktop](https://rancherdesktop.io)
      * [Podman Desktop](https://podman-desktop.io)
   2. [node](https://nodejs.org/en/download/package-manager)
   3. [golang](https://go.dev/doc/install)
   4. [geos](https://libgeos.org/usage/install/)
   5. [make](https://formulae.brew.sh/formula/make)
3. Map `local-dsp.virtru.com` to `localhost` in your hosts file

      To ensure all PEPs can operate we need to map a local domain to the your localhost.
      In \*nix environments your hosts file is located at `/etc/hosts` and windows is typically `C:\Windows\System32\drivers\etc`.

      > [!NOTE]
      > You will probably need to use root permisisons (i.e. `sudo`) to edit your hosts file.

      ```shell
      127.0.0.1            local-dsp.virtru.com
      ```

4. Use Mkcert for local development

      We use `mkcert` to generate certs for local development. This is required for the `local-dsp.virtru.com` domain.

      ```shell
      brew install mkcert
      ```

      Next follow these steps to generate the certs:

      ```shell
      # Create the keys dir
      mkdir -p dsp-keys
      # Install the CA
      mkcert -install
      # Generate the certs
      mkcert -cert-file dsp-keys/local-dsp.virtru.com.pem -key-file dsp-keys/local-dsp.virtru.com.key.pem local-dsp.virtru.com "*.local-dsp.virtru.com" localhost
      # Generate keys for KAS and PolicyImportExport artifact signing
      ./.github/scripts/init-temp-keys.sh
      # OPTIONAL: generate temporary x509 certificates
      ./.github/scripts/x509-temp-keys.sh
      ```

      > Note: you can use `'make dev-certs'` as a shortcut to generate the development certs

5. Google Artifact Registry for DSP Images

      DSP images (and possibly others in the future) are published to Google Artifact Registry and therefore auth to the registry is required:

      * Install gcloud cli [install directions](https://cloud.google.com/sdk/docs/install-sdk)
      * Authenticate (or re-authenticate; the Auth token is normally good for 1 hour):

      ```shell
      gcloud auth login
      ```

      * Authenticate to GCP registry to allow pulls:

      ```shell
      gcloud auth print-access-token | docker login -u oauth2accesstoken --password-stdin https://us-docker.pkg.dev
      ```

### Start required services

Create and start containers

```sh
  docker-compose -f docker-compose.dev.yaml up
```

This starts the following services:

1. [COP database](./compose/docker-compose.cop-db.yaml)
2. [Keycloak](./compose/docker-compose.keycloak.yaml)
3. [Data Security Platform (DSP)](./compose/docker-compose.dsp.yaml)
   1. Provision keycloak with sample users and clients
   2. Setup the database
   3. Start the DSP server
   4. Load the sample policy
4. [NiFi](./compose/docker-compose.nifi.yaml) (_disabled by default_)
   > [!NOTE]
   > Nifi is resource-intensive, so you should run `colima` with extra resources allocated: `colima start --memory 16 --cpu 6`
   1. For local docker compose, run the [build_truststore_local.sh](./build_truststore_local.sh)  to build a truststore for use with NiFi and Tagging Services
   2. Copy the trusted cert for tagging pdp use to it's mounted drive: `cp ./dsp-keys/local-dsp.virtru.com.pem ./nifi/truststore`
   3. Run with envfile and nifi profile enabled: `docker-compose --profile nifi -f docker-compose.dev.yaml --env-file=./env/default.env up`
      * Note that NiFi uses significant resources; ensure your docker env has sufficient resources allocated

### Run the COP Server

> [!NOTE]
> To run without mocked static assets, must have followed [frontend README](/ui/README.md).

```bash
# Run server with mock frontend assets
go run . serve
```

#### Run with static assets

To run the server with the statically built COP frontend. (See [ui README](/ui/README.md) for more information.)

```bash
go run -tags embedfiles . serve
```

### Web UI

Run the web UI in development mode

```shell
# in context of web ui
cd ui
# copy the .env.example to .env
cp .env.example .env
# switch to required node engine
nvm use
# install app dependencies
npm ci
# start the development server
npm start
```

See the [ui README](/ui/README.md) for more information on the frontend development environment including **running statically built assets.**

### Authentication

DSP-COP supports two authentication flows:
1. Username/Password (default)
   - user enters credentials into application form, application initiates token request 
2. Keycloak Authentication (PKI/x509 or username/password)
   - Application redirects user to Keycloak for authentication, keycloak returns a token

To enable the Keycloak authentication flow, set the following value in the `ui/.env`
   - `VITE_DSP_KC_DIRECT_AUTH=true`

To enable and configure x509 based login, see `x509.md`

---

## Production

> [!NOTE]
> When running in production you will most likely need to set the `service.public_server_host` and the `service.public_static_host` to the appropriate domain and port. This is required when the server is running behind a reverse proxy.

*Details on running in production is not yet available.*

## Schema Creation

Within COP, we refer to the individual data entities used by the system as "Source Types". Each Source Type has a configuration that defines the structure and behavior of the data ("form schema"), how the data is displayed and interacted with from the UI ("UI schema"), and additional information on how this data entity is used by the application ("metadata"). These configurations are stored in the database and are used to generate the forms and UI elements that users interact with when creating and viewing data in COP.

### Database Structure

Source Type configurations are stored in the `src_types` table of the database.  Each column besides the unique `id` uses the JSONB data type to store the schema configuration as JSON data. The columns are as follows (see the [entity relationship diagram](./db/entityRelationshipDiagram.md) for more details):

```postgresql
id TEXT
form_schema JSONB
ui_schema JSONB
metadata JSONB
```

### Creating a new Source Type

At the time of this writing, Source Type creation is a manual process using a SQL seed data script that is run when composing up with docker. This seed script can be found at [db/seed.sql](db/seed.sql) and can be modified to include as many source types as desired. In the future, this may be replaced with YAML files that are easier to read/maintain, or even managed within the COP application directly from an admin page.

To create the JSON data stored by each column, use your favorite JSON text editor and then serialize the JSON to a string using an online tool or your preferred language's library (e.g. `JSON.stringify` with JavaScript). Once you have the string, add it to the seed script in the appropriate column.

Two different source types are currently pre-defined in the seed script: `sitrep` and `employee`.  Please refer to these examples for further guidance beyond this documentation when creating the JSONB values for each column.

#### Defining the Form Schema

The Form Schema is defined using the [JSON Schema specification](https://json-schema.org/). This schema defines the structure of the data for the Source Type. The schema is later used with the UI to generate the form fields for entering data, as well as validate the data entered by the user in those form fields.

COP uses the [react-jsonschema-form](https://rjsf-team.github.io/react-jsonschema-form/docs/) library for generating these forms.

#### Defining the UI Schema

The UI Schema is defined using a standard JSON object, but its structure is coupled to the React library mentioned above for form generation. Thus, the format of the JSON object here must follow the defined [UI Schema API structure](https://rjsf-team.github.io/react-jsonschema-form/docs/api-reference/uiSchema).

To learn more about how the Form and UI Schemas work together, visit the [React JSON Schema Form Playground](https://rjsf-team.github.io/react-jsonschema-form/). You can experiment with different JSON and UI Schema configurations to see how they affect the form rendering and behavior.

#### Defining the Metadata

The Metadata is defined using a standard JSON object with a known structure of key/value pairs. It can evolve as requirements change, but the current structure is as follows:

`geoField` _string_ - The name of the form schema field that should be used for location data when writing to the `tdf_objects.geo` database table column.

`searchFields` _string[]_ - An array of form schema field names that should be used when writing JSONB searchable key/value pairs in unencrypted plaintext to the `tdf_objects.search` database table column.

`attrFields` _string[]_ - An array of form schema field names that define the fields used for access control when encrypting data as a TDF to be stored in the `tdf_objects.tdf_blob` database table column.

`tsField` _string_ - The name of the form schema field that should be used for the timestamp when writing to the `tdf_objects.ts` database table column.  If not defined, the database will use the current timestamp by default.

`displayFields` _object_ - An object with two keys: `header` and `details`. The `header` key is a string that defines the form schema field name to be used as the header when displaying the data in the UI. The `details` key is an array of strings that define the form schema field names to be used as the detail list when displaying data in the UI.

`mapFields` _object_ - An object with four keys: `iconDefault`, `iconConfig`, `colorDefault` and `colorConfig`. This object defines the form schema field names to be used when customizing the map marker icon and color. The `iconDefault` and `colorDefault` keys define the default icon and color mapping to be used when no other mapping is defined. The `iconConfig` and `colorConfig` keys are arrays of objects that define the field names and values to be used for mapping those field values to the proper icons and colors within the COP UI.

#### Using `dsp` and `dsp tructl` for development

After provisioning the developer's local stack, the following workflow
may be used to interact with the `dsp` and `dsp tructl` CLIs.

```bash
# Open a shell
make launch-dsp-shell

# Once inside, access tructl functionality
dsp tructl --with-client-creds '{"clientId":"opentdf","clientSecret":"secret"}' policy attributes list --host https://local-dsp.virtru.com:8080 --tls-no-verify
```

## Known Issues

* Update create RPC handler returns an empty UUID if the insert fails due to a failure to connect to DB
* SITREP form CSS and asterisks for required fields do not match validation (which contains the real requirements logic)
* Possible to zoom out the map and see countries multiple times with only single pins rendered
* Autocomplete in form UI is unintuitive
* When searching, no UI validation of start and end date/time
   * start date is required 
   * start date must be before end date
* URL search params are not cleared when swithing between source types, resulting in unrelated params breaking search
* Source Type is NULLable and should be required
* Passing a non-existent source type for the `type` URL param in the SourceTypes component, breaks the selector and page components